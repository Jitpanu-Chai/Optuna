{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optuna_FashionMNIST_plusconvo_batchsize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOEnm5Zks1o7lQpjGnMmS0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jitpanu-Chai/Optuna/blob/main/Optuna_FashionMNIST_plusconvo_batchsize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auo5nTwryopW",
        "outputId": "d97d4c81-4e18-4f32-d88a-11fdb253c8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 308 kB 7.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 210 kB 65.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 113 kB 83.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 90.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.7 MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qq optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import os"
      ],
      "metadata": {
        "id": "AKVDFORkraXK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch**"
      ],
      "metadata": {
        "id": "yDYMQt6VhzoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import math"
      ],
      "metadata": {
        "id": "PLS6a8I43SUu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\") #torch.device(\"cpu\")\n",
        "# BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 10\n",
        "LOG_INTERVAL = 10\n",
        "# N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "# N_VALID_EXAMPLES = BATCHSIZE * 10"
      ],
      "metadata": {
        "id": "vUXPXoPW_-Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optuna+Model construct**"
      ],
      "metadata": {
        "id": "ZxVKbLo76jLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.MaxPool2d((2,2))\n",
        "# pool of non-square window\n",
        "# m = nn.MaxPool2d((3, 2), stride=(2, 1))\n",
        "input = torch.randn(20, 56, 2, 2)\n",
        "output = m(input)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpOWPU29kMZW",
        "outputId": "36f12de4-21c6-48a4-a5fc-acdf2ec9c9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 56, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "math.floor(( (28 +2*0-1*(3-1)-1  ) /1)+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGooPcVRo5RG",
        "outputId": "c270ab13-0abc-4ecd-c516-ae16455edad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_shape_after_convo(in_shape,kernel_size=1,dilation=1,stride=1,padding='same'):  #same padd=0\n",
        "    if padding != 'same':\n",
        "        new_shape = math.floor(( (in_shape +2*padding-dilation*(kernel_size-1)-1  ) /stride)+1)\n",
        "    else:\n",
        "        new_shape = in_shape\n",
        "    return new_shape\n"
      ],
      "metadata": {
        "id": "HdNo-csCnDep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "    #optmize number of layer ,hidden unit drop out\n",
        "    n_layers = trial.suggest_int(\"n_layers\",1,3)\n",
        "    n_blocks = trial.suggest_int(\"n_blocks\", 2, 5)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n",
        "\n",
        "    layers=[]\n",
        "    # in_features = 28*28\n",
        "    in_features = 1 #init channel (fasjon MNIST is 1 due to greyscale)    \n",
        "    squre_shape = 28\n",
        "\n",
        "    #convo block\n",
        "    for i in range(1,n_blocks):\n",
        "        kernal_select = trial.suggest_int(\"kernal_units_l{}\".format(i),3,7)\n",
        "\n",
        "        out_features = i*28 # how many times of it shape (28,28)\n",
        "        layers.append(nn.Conv2d(in_features,out_features,kernel_size=kernal_select,padding='same'))\n",
        "        squre_shape = cal_shape_after_convo(squre_shape,kernel_size=kernal_select)\n",
        "       \n",
        "       \n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.BatchNorm2d(out_features))\n",
        "\n",
        "        in_features = out_features\n",
        "        layers.append(nn.Conv2d(in_features,out_features,kernel_size=kernal_select,padding='same'))\n",
        "        squre_shape = cal_shape_after_convo(squre_shape,kernel_size=kernal_select)\n",
        "       \n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.BatchNorm2d(out_features))\n",
        "\n",
        "        layers.append(nn.MaxPool2d((2,2)))\n",
        "        squre_shape = math.floor(squre_shape/2)\n",
        "               \n",
        "        layers.append(nn.Dropout(0.5))\n",
        "            \n",
        " \n",
        "    layers.append(nn.Flatten())\n",
        "\n",
        "    in_features = in_features*squre_shape*squre_shape    \n",
        "\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i),16,512)\n",
        "        layers.append(nn.Linear(in_features,out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p= trial.suggest_float(\"dropout_l{}\".format(i),0.2,0.8)\n",
        "        layers.append(nn.Dropout(p))\n",
        "        in_features=out_features\n",
        "\n",
        "    layers.append(nn.Linear(in_features,CLASSES))\n",
        "    layers.append(nn.LogSoftmax(dim=1))\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "hSZC7KzyYeRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist(BATCHSIZE):\n",
        "    # Load FashionMNIST dataset.\n",
        "    transform = transforms.Compose([transforms.ToTensor(),])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transform),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=False, transform=transform),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "RedG1oQ4ALDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optuna Area**"
      ],
      "metadata": {
        "id": "rNpxXUDX2_qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    #code here\n",
        "    #create model\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "  \n",
        "    #create optimize\n",
        "    optimizer_name=trial.suggest_categorical(\"optimizers\",[\"Adam\",\"RMSprop\",\"SGD\"])\n",
        "    lr= trial.suggest_float(\"lr\",1e-5,1e-1,log=True)\n",
        "    optimizer= getattr(optim, optimizer_name)(model.parameters(),lr=lr)\n",
        "\n",
        "    #create batchsize select\n",
        "    BATCHSIZE = trial.suggest_categorical(\"n_batch\", [32,64,128,256,512,1024])\n",
        "\n",
        "    N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "    N_VALID_EXAMPLES = BATCHSIZE * 10\n",
        "\n",
        "    #get MNIST dataset\n",
        "    train_loader,valid_loader = get_mnist(BATCHSIZE)\n",
        "\n",
        "    #train model\n",
        "    for eporch in range(EPOCHS):\n",
        "        #train torch code model\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1,28,28).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1,28,28).to(DEVICE), target.to(DEVICE)\n",
        "                \n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy,eporch) #report to optuna to check status its worth or not\n",
        "        #handing prun algo\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()    \n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "-o1ru4nG2aDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if __name__ == 'main':\n",
        "\n",
        "study = optuna.create_study(direction='maximize') #select own direction or default\n",
        "study.optimize(objective,n_trials=100) #number of trials #timeout=600\n",
        "\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
        "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "\n",
        "print('study statistic')\n",
        "print('number of finished trials: ',len(study.trials))\n",
        "print('number of proned trials: ',len(pruned_trials))\n",
        "print('number of completed trials: ',len(complete_trials))\n",
        "\n",
        "print(\"Best trials:\")\n",
        "trial =study.best_trial\n",
        "print('Value', trial.value)\n",
        "\n",
        "print('Params')\n",
        "for key,value in trial.params.items():\n",
        "    print('{}:{}'.format(key,value))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYK5WbT6899n",
        "outputId": "78237f34-5675-4268-8da5-073c78f0988d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-02 16:32:48,856]\u001b[0m A new study created in memory with name: no-name-0157fc21-fb17-4ed4-bb46-b62ae0eedf03\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:32:59,359]\u001b[0m Trial 0 finished with value: 0.671875 and parameters: {'n_layers': 3, 'n_blocks': 2, 'weight_decay': 5.0613861051247375e-09, 'kernal_units_l1': 3, 'n_units_l0': 285, 'dropout_l0': 0.7523013863712733, 'n_units_l1': 244, 'dropout_l1': 0.44611666708747577, 'n_units_l2': 152, 'dropout_l2': 0.3253678146645078, 'optimizers': 'RMSprop', 'lr': 1.3281683011527026e-05, 'n_batch': 256}. Best is trial 0 with value: 0.671875.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:33:02,945]\u001b[0m Trial 1 finished with value: 0.728125 and parameters: {'n_layers': 1, 'n_blocks': 3, 'weight_decay': 7.421792212677782e-05, 'kernal_units_l1': 3, 'kernal_units_l2': 7, 'n_units_l0': 168, 'dropout_l0': 0.6956880436641028, 'optimizers': 'SGD', 'lr': 0.0023737527008802217, 'n_batch': 64}. Best is trial 1 with value: 0.728125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:444: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:744.)\n",
            "  self.padding, self.dilation, self.groups)\n",
            "\u001b[32m[I 2022-05-02 16:33:05,565]\u001b[0m Trial 2 finished with value: 0.803125 and parameters: {'n_layers': 1, 'n_blocks': 3, 'weight_decay': 5.0142491858888495e-06, 'kernal_units_l1': 6, 'kernal_units_l2': 4, 'n_units_l0': 236, 'dropout_l0': 0.5739676294084706, 'optimizers': 'SGD', 'lr': 0.03854042983967213, 'n_batch': 32}. Best is trial 2 with value: 0.803125.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:26,825]\u001b[0m Trial 3 finished with value: 0.1255 and parameters: {'n_layers': 3, 'n_blocks': 4, 'weight_decay': 8.467225918388979e-06, 'kernal_units_l1': 6, 'kernal_units_l2': 6, 'kernal_units_l3': 6, 'n_units_l0': 482, 'dropout_l0': 0.6004275999555342, 'n_units_l1': 449, 'dropout_l1': 0.2168715172654575, 'n_units_l2': 196, 'dropout_l2': 0.6996361342700124, 'optimizers': 'RMSprop', 'lr': 0.03931746357302113, 'n_batch': 1024}. Best is trial 2 with value: 0.803125.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:30,639]\u001b[0m Trial 4 finished with value: 0.8265625 and parameters: {'n_layers': 2, 'n_blocks': 3, 'weight_decay': 5.762955924219621e-08, 'kernal_units_l1': 7, 'kernal_units_l2': 5, 'n_units_l0': 295, 'dropout_l0': 0.3037089101418451, 'n_units_l1': 385, 'dropout_l1': 0.2644069575824007, 'optimizers': 'SGD', 'lr': 0.03476508630658996, 'n_batch': 64}. Best is trial 4 with value: 0.8265625.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:30,945]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:34,695]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:35,439]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:36,158]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:39,713]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:40,242]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:40,594]\u001b[0m Trial 11 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:42,612]\u001b[0m Trial 12 finished with value: 0.78125 and parameters: {'n_layers': 1, 'n_blocks': 2, 'weight_decay': 4.867369516238986e-07, 'kernal_units_l1': 6, 'n_units_l0': 192, 'dropout_l0': 0.5396265434919435, 'optimizers': 'SGD', 'lr': 0.004838991296131547, 'n_batch': 32}. Best is trial 4 with value: 0.8265625.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:34:43,250]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:35:11,323]\u001b[0m Trial 14 finished with value: 0.8591796875 and parameters: {'n_layers': 2, 'n_blocks': 3, 'weight_decay': 1.695508643674089e-06, 'kernal_units_l1': 6, 'kernal_units_l2': 4, 'n_units_l0': 249, 'dropout_l0': 0.2024039487167889, 'n_units_l1': 290, 'dropout_l1': 0.2410650665200742, 'optimizers': 'SGD', 'lr': 0.05451371006475575, 'n_batch': 512}. Best is trial 14 with value: 0.8591796875.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:35:14,336]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:35:35,193]\u001b[0m Trial 16 finished with value: 0.9037109375 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.4970113647651826e-09, 'kernal_units_l1': 6, 'n_units_l0': 131, 'dropout_l0': 0.308344135218813, 'n_units_l1': 206, 'dropout_l1': 0.3158724327417511, 'optimizers': 'Adam', 'lr': 0.001610932472369899, 'n_batch': 512}. Best is trial 16 with value: 0.9037109375.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:35:53,645]\u001b[0m Trial 17 finished with value: 0.8576171875 and parameters: {'n_layers': 3, 'n_blocks': 2, 'weight_decay': 2.422437253639332e-09, 'kernal_units_l1': 5, 'n_units_l0': 127, 'dropout_l0': 0.30590958540703683, 'n_units_l1': 131, 'dropout_l1': 0.3438816281540983, 'n_units_l2': 484, 'dropout_l2': 0.21796707204542765, 'optimizers': 'Adam', 'lr': 0.00010443815359660067, 'n_batch': 512}. Best is trial 16 with value: 0.9037109375.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:36:12,009]\u001b[0m Trial 18 finished with value: 0.9048828125 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.174052577339951e-09, 'kernal_units_l1': 4, 'n_units_l0': 96, 'dropout_l0': 0.20056333614617228, 'n_units_l1': 195, 'dropout_l1': 0.5630691567072538, 'optimizers': 'Adam', 'lr': 0.001515835604806812, 'n_batch': 512}. Best is trial 18 with value: 0.9048828125.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:36:31,091]\u001b[0m Trial 19 finished with value: 0.8978515625 and parameters: {'n_layers': 3, 'n_blocks': 2, 'weight_decay': 1.0592981085404046e-09, 'kernal_units_l1': 4, 'n_units_l0': 89, 'dropout_l0': 0.35981318371954274, 'n_units_l1': 202, 'dropout_l1': 0.5763626133012991, 'n_units_l2': 447, 'dropout_l2': 0.4913099299719592, 'optimizers': 'Adam', 'lr': 0.0011509217264618465, 'n_batch': 512}. Best is trial 18 with value: 0.9048828125.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:36:41,125]\u001b[0m Trial 20 finished with value: 0.869921875 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.0366057594510816e-08, 'kernal_units_l1': 4, 'n_units_l0': 28, 'dropout_l0': 0.2647623538659219, 'n_units_l1': 172, 'dropout_l1': 0.530843796078654, 'optimizers': 'Adam', 'lr': 0.0016040602722409395, 'n_batch': 256}. Best is trial 18 with value: 0.9048828125.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:36:59,872]\u001b[0m Trial 21 finished with value: 0.88671875 and parameters: {'n_layers': 3, 'n_blocks': 2, 'weight_decay': 1.1222546544395331e-09, 'kernal_units_l1': 4, 'n_units_l0': 99, 'dropout_l0': 0.3786257000014285, 'n_units_l1': 190, 'dropout_l1': 0.5752519589974349, 'n_units_l2': 438, 'dropout_l2': 0.5100138423165149, 'optimizers': 'Adam', 'lr': 0.0005964117607144462, 'n_batch': 512}. Best is trial 18 with value: 0.9048828125.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:37:18,383]\u001b[0m Trial 22 finished with value: 0.8818359375 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 5.670610298866397e-10, 'kernal_units_l1': 4, 'n_units_l0': 130, 'dropout_l0': 0.3621763639744148, 'n_units_l1': 37, 'dropout_l1': 0.6177637464657826, 'optimizers': 'Adam', 'lr': 0.0038771208484059583, 'n_batch': 512}. Best is trial 18 with value: 0.9048828125.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:37:20,267]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:37:38,803]\u001b[0m Trial 24 finished with value: 0.9013671875 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.773037757494015e-09, 'kernal_units_l1': 4, 'n_units_l0': 130, 'dropout_l0': 0.26498274838590186, 'n_units_l1': 130, 'dropout_l1': 0.516142456487507, 'optimizers': 'Adam', 'lr': 0.0010904276542245586, 'n_batch': 512}. Best is trial 18 with value: 0.9048828125.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:37:57,105]\u001b[0m Trial 25 finished with value: 0.9087890625 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 2.7568750073666043e-09, 'kernal_units_l1': 5, 'n_units_l0': 154, 'dropout_l0': 0.2550922164243307, 'n_units_l1': 128, 'dropout_l1': 0.4691597404267786, 'optimizers': 'Adam', 'lr': 0.0006610004840350657, 'n_batch': 512}. Best is trial 25 with value: 0.9087890625.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:37:59,006]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:38:20,302]\u001b[0m Trial 27 finished with value: 0.8916015625 and parameters: {'n_layers': 2, 'n_blocks': 3, 'weight_decay': 1.320410769008298e-07, 'kernal_units_l1': 5, 'kernal_units_l2': 6, 'n_units_l0': 147, 'dropout_l0': 0.2095561144833145, 'n_units_l1': 62, 'dropout_l1': 0.4571505000351171, 'optimizers': 'Adam', 'lr': 0.000667520998323524, 'n_batch': 512}. Best is trial 25 with value: 0.9087890625.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:38:24,528]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:38:25,568]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:38:27,813]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:38:46,369]\u001b[0m Trial 31 finished with value: 0.9091796875 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 3.799100585352424e-09, 'kernal_units_l1': 4, 'n_units_l0': 159, 'dropout_l0': 0.26956801112032275, 'n_units_l1': 96, 'dropout_l1': 0.5135306150362473, 'optimizers': 'Adam', 'lr': 0.0012130928333545633, 'n_batch': 512}. Best is trial 31 with value: 0.9091796875.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:04,817]\u001b[0m Trial 32 finished with value: 0.893359375 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 3.617800682526101e-09, 'kernal_units_l1': 3, 'n_units_l0': 160, 'dropout_l0': 0.23882800839496468, 'n_units_l1': 96, 'dropout_l1': 0.5625584666517512, 'optimizers': 'Adam', 'lr': 0.0018137998422157026, 'n_batch': 512}. Best is trial 31 with value: 0.9091796875.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:06,715]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:08,933]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:10,928]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:15,230]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:22,103]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:24,277]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:24,733]\u001b[0m Trial 39 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:25,369]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:39:43,922]\u001b[0m Trial 41 finished with value: 0.9076171875 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 2.013693049383939e-09, 'kernal_units_l1': 4, 'n_units_l0': 143, 'dropout_l0': 0.3254143521171552, 'n_units_l1': 120, 'dropout_l1': 0.5220315198311817, 'optimizers': 'Adam', 'lr': 0.0009621452082759439, 'n_batch': 512}. Best is trial 31 with value: 0.9091796875.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:40:02,443]\u001b[0m Trial 42 finished with value: 0.896484375 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 7.660510041419761e-09, 'kernal_units_l1': 4, 'n_units_l0': 172, 'dropout_l0': 0.3278719602034505, 'n_units_l1': 60, 'dropout_l1': 0.599658733640545, 'optimizers': 'Adam', 'lr': 0.0004878394497566174, 'n_batch': 512}. Best is trial 31 with value: 0.9091796875.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:40:20,618]\u001b[0m Trial 43 finished with value: 0.89453125 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 2.553900778198504e-10, 'kernal_units_l1': 3, 'n_units_l0': 131, 'dropout_l0': 0.29183727750922434, 'n_units_l1': 173, 'dropout_l1': 0.4591868229219137, 'optimizers': 'Adam', 'lr': 0.0008384186428220812, 'n_batch': 512}. Best is trial 31 with value: 0.9091796875.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:40:20,914]\u001b[0m Trial 44 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:40:24,611]\u001b[0m Trial 45 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:40:27,361]\u001b[0m Trial 46 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:41:01,695]\u001b[0m Trial 47 finished with value: 0.9145 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 2.8689128261368593e-08, 'kernal_units_l1': 4, 'n_units_l0': 254, 'dropout_l0': 0.34282337679484753, 'n_units_l1': 152, 'dropout_l1': 0.4330725940202829, 'optimizers': 'Adam', 'lr': 0.0008387710482018789, 'n_batch': 1024}. Best is trial 47 with value: 0.9145.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:41:08,607]\u001b[0m Trial 48 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:41:12,499]\u001b[0m Trial 49 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:41:46,720]\u001b[0m Trial 50 finished with value: 0.906 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.4438488655827205e-07, 'kernal_units_l1': 4, 'n_units_l0': 499, 'dropout_l0': 0.22132215617884696, 'n_units_l1': 112, 'dropout_l1': 0.4746777748241936, 'optimizers': 'Adam', 'lr': 0.0002138363706079179, 'n_batch': 1024}. Best is trial 47 with value: 0.9145.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:42:21,186]\u001b[0m Trial 51 finished with value: 0.902 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.5555942060281013e-06, 'kernal_units_l1': 4, 'n_units_l0': 499, 'dropout_l0': 0.22223110438831212, 'n_units_l1': 110, 'dropout_l1': 0.4729826173121848, 'optimizers': 'Adam', 'lr': 0.00018256097671439408, 'n_batch': 1024}. Best is trial 47 with value: 0.9145.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:42:24,657]\u001b[0m Trial 52 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:42:59,458]\u001b[0m Trial 53 finished with value: 0.9133 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 3.3171546223105304e-08, 'kernal_units_l1': 4, 'n_units_l0': 455, 'dropout_l0': 0.25491011964078353, 'n_units_l1': 140, 'dropout_l1': 0.5036227904894387, 'optimizers': 'Adam', 'lr': 0.0004659079257959436, 'n_batch': 1024}. Best is trial 47 with value: 0.9145.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:43:02,912]\u001b[0m Trial 54 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:43:06,440]\u001b[0m Trial 55 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:43:41,134]\u001b[0m Trial 56 finished with value: 0.9103 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.006439181552819e-07, 'kernal_units_l1': 5, 'n_units_l0': 503, 'dropout_l0': 0.2531163883970429, 'n_units_l1': 144, 'dropout_l1': 0.5064303038976652, 'optimizers': 'Adam', 'lr': 0.00030760281483487544, 'n_batch': 1024}. Best is trial 47 with value: 0.9145.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:43:45,534]\u001b[0m Trial 57 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:43:45,947]\u001b[0m Trial 58 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:43:46,225]\u001b[0m Trial 59 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:43:49,737]\u001b[0m Trial 60 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:43:53,306]\u001b[0m Trial 61 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:44:27,392]\u001b[0m Trial 62 finished with value: 0.9135 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 3.810538328006179e-07, 'kernal_units_l1': 4, 'n_units_l0': 360, 'dropout_l0': 0.2531782207281151, 'n_units_l1': 122, 'dropout_l1': 0.4797542933282788, 'optimizers': 'Adam', 'lr': 0.0007431506959975354, 'n_batch': 1024}. Best is trial 47 with value: 0.9145.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:44:30,840]\u001b[0m Trial 63 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:45:05,146]\u001b[0m Trial 64 finished with value: 0.9148 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.5104666586823521e-05, 'kernal_units_l1': 4, 'n_units_l0': 387, 'dropout_l0': 0.2914373424222511, 'n_units_l1': 140, 'dropout_l1': 0.5081001536108833, 'optimizers': 'Adam', 'lr': 0.0006562493001340525, 'n_batch': 1024}. Best is trial 64 with value: 0.9148.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:45:39,181]\u001b[0m Trial 65 finished with value: 0.9147 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 5.722018089074057e-06, 'kernal_units_l1': 5, 'n_units_l0': 360, 'dropout_l0': 0.30337335712819236, 'n_units_l1': 141, 'dropout_l1': 0.40627567065450865, 'optimizers': 'Adam', 'lr': 0.0006143601348509423, 'n_batch': 1024}. Best is trial 64 with value: 0.9148.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:46:13,194]\u001b[0m Trial 66 finished with value: 0.9094 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 2.036924836365081e-05, 'kernal_units_l1': 4, 'n_units_l0': 386, 'dropout_l0': 0.30550083543359474, 'n_units_l1': 184, 'dropout_l1': 0.40895278346759745, 'optimizers': 'Adam', 'lr': 0.0003215150126090176, 'n_batch': 1024}. Best is trial 64 with value: 0.9148.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:46:17,796]\u001b[0m Trial 67 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:46:51,810]\u001b[0m Trial 68 finished with value: 0.9145 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 5.417340207577588e-06, 'kernal_units_l1': 4, 'n_units_l0': 359, 'dropout_l0': 0.3489427585728377, 'n_units_l1': 231, 'dropout_l1': 0.40663246348782484, 'optimizers': 'Adam', 'lr': 0.0003341754650106639, 'n_batch': 1024}. Best is trial 64 with value: 0.9148.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:47:25,633]\u001b[0m Trial 69 finished with value: 0.9141 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 4.388327046439114e-06, 'kernal_units_l1': 3, 'n_units_l0': 354, 'dropout_l0': 0.3464515524688246, 'n_units_l1': 273, 'dropout_l1': 0.38530096365107425, 'optimizers': 'Adam', 'lr': 0.0005801747010626423, 'n_batch': 1024}. Best is trial 64 with value: 0.9148.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:47:29,204]\u001b[0m Trial 70 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:47:32,711]\u001b[0m Trial 71 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:48:06,750]\u001b[0m Trial 72 finished with value: 0.9129 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 6.58664323069331e-05, 'kernal_units_l1': 3, 'n_units_l0': 306, 'dropout_l0': 0.36944400304799757, 'n_units_l1': 265, 'dropout_l1': 0.32694088945544114, 'optimizers': 'Adam', 'lr': 0.0003448902383000432, 'n_batch': 1024}. Best is trial 64 with value: 0.9148.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:48:40,230]\u001b[0m Trial 73 finished with value: 0.9106 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 6.852466387154823e-05, 'kernal_units_l1': 3, 'n_units_l0': 318, 'dropout_l0': 0.3732334600078944, 'n_units_l1': 253, 'dropout_l1': 0.3248699276019884, 'optimizers': 'Adam', 'lr': 0.0004134539586531475, 'n_batch': 1024}. Best is trial 64 with value: 0.9148.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:48:43,691]\u001b[0m Trial 74 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:48:47,207]\u001b[0m Trial 75 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:48:50,695]\u001b[0m Trial 76 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:48:51,747]\u001b[0m Trial 77 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:48:52,919]\u001b[0m Trial 78 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:49:00,181]\u001b[0m Trial 79 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:49:03,674]\u001b[0m Trial 80 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:49:37,587]\u001b[0m Trial 81 finished with value: 0.9145 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 4.737534787713515e-05, 'kernal_units_l1': 3, 'n_units_l0': 318, 'dropout_l0': 0.4178120165956394, 'n_units_l1': 258, 'dropout_l1': 0.31807472841890727, 'optimizers': 'Adam', 'lr': 0.0004312540891559199, 'n_batch': 1024}. Best is trial 64 with value: 0.9148.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:50:11,600]\u001b[0m Trial 82 finished with value: 0.9189 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 4.7274119135084036e-05, 'kernal_units_l1': 3, 'n_units_l0': 362, 'dropout_l0': 0.4181671524652524, 'n_units_l1': 262, 'dropout_l1': 0.3221445951766942, 'optimizers': 'Adam', 'lr': 0.0007623074661478627, 'n_batch': 1024}. Best is trial 82 with value: 0.9189.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:50:45,301]\u001b[0m Trial 83 finished with value: 0.9178 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.0866497754601519e-05, 'kernal_units_l1': 3, 'n_units_l0': 366, 'dropout_l0': 0.41860791166736516, 'n_units_l1': 305, 'dropout_l1': 0.28200044221051906, 'optimizers': 'Adam', 'lr': 0.0009079759730425497, 'n_batch': 1024}. Best is trial 82 with value: 0.9189.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:50:48,742]\u001b[0m Trial 84 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:50:52,205]\u001b[0m Trial 85 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:50:52,611]\u001b[0m Trial 86 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:50:56,032]\u001b[0m Trial 87 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:51:29,948]\u001b[0m Trial 88 finished with value: 0.9185 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 1.5033577695915971e-05, 'kernal_units_l1': 3, 'n_units_l0': 328, 'dropout_l0': 0.34799343396627935, 'n_units_l1': 275, 'dropout_l1': 0.3350253450151808, 'optimizers': 'Adam', 'lr': 0.0008153712013180436, 'n_batch': 1024}. Best is trial 82 with value: 0.9189.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:51:30,247]\u001b[0m Trial 89 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:51:33,660]\u001b[0m Trial 90 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:51:37,108]\u001b[0m Trial 91 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:52:11,007]\u001b[0m Trial 92 finished with value: 0.9168 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 3.465581474179938e-05, 'kernal_units_l1': 3, 'n_units_l0': 345, 'dropout_l0': 0.4367434959168928, 'n_units_l1': 336, 'dropout_l1': 0.27937449017078453, 'optimizers': 'Adam', 'lr': 0.0005454669864059432, 'n_batch': 1024}. Best is trial 82 with value: 0.9189.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:52:44,994]\u001b[0m Trial 93 finished with value: 0.9104 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 4.1497661288125325e-05, 'kernal_units_l1': 3, 'n_units_l0': 341, 'dropout_l0': 0.39308123513741805, 'n_units_l1': 346, 'dropout_l1': 0.2490172208405143, 'optimizers': 'Adam', 'lr': 0.0005335910849941994, 'n_batch': 1024}. Best is trial 82 with value: 0.9189.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:52:45,618]\u001b[0m Trial 94 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:52:46,659]\u001b[0m Trial 95 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:52:56,945]\u001b[0m Trial 96 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:53:30,814]\u001b[0m Trial 97 finished with value: 0.9182 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 6.6694528337203775e-06, 'kernal_units_l1': 3, 'n_units_l0': 431, 'dropout_l0': 0.36302675184531213, 'n_units_l1': 361, 'dropout_l1': 0.23052114795752912, 'optimizers': 'Adam', 'lr': 0.0005815101286994761, 'n_batch': 1024}. Best is trial 82 with value: 0.9189.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:54:09,913]\u001b[0m Trial 98 finished with value: 0.9099 and parameters: {'n_layers': 2, 'n_blocks': 2, 'weight_decay': 0.00018740858231651005, 'kernal_units_l1': 7, 'n_units_l0': 426, 'dropout_l0': 0.3586957488264241, 'n_units_l1': 369, 'dropout_l1': 0.22281248526756858, 'optimizers': 'Adam', 'lr': 0.0003858395835975563, 'n_batch': 1024}. Best is trial 82 with value: 0.9189.\u001b[0m\n",
            "\u001b[32m[I 2022-05-02 16:54:13,726]\u001b[0m Trial 99 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "study statistic\n",
            "number of finished trials:  100\n",
            "number of proned trials:  57\n",
            "number of completed trials:  43\n",
            "Best trials:\n",
            "Value 0.9189\n",
            "Params\n",
            "n_layers:2\n",
            "n_blocks:2\n",
            "weight_decay:4.7274119135084036e-05\n",
            "kernal_units_l1:3\n",
            "n_units_l0:362\n",
            "dropout_l0:0.4181671524652524\n",
            "n_units_l1:262\n",
            "dropout_l1:0.3221445951766942\n",
            "optimizers:Adam\n",
            "lr:0.0007623074661478627\n",
            "n_batch:1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow**"
      ],
      "metadata": {
        "id": "cQdGvvhGh6ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "oQByqDsSmAlR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# N_TRAIN_EXAMPLES = 3000\n",
        "# N_VALID_EXAMPLES = 1000\n",
        "# BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "dm4LJ2gzh5Ng"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(trial):\n",
        "    # We optimize the numbers of layers, their units and weight decay parameter.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    n_blocks = trial.suggest_int(\"n_blocks\", 2, 5)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n",
        "\n",
        "    num_filters2=28\n",
        "    drop_dense2=0.5\n",
        "    drop_conv2=0\n",
        "    num_classes = 10\n",
        "    ac2='relu'\n",
        "    reg2=None\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Input((28, 28, 3)))\n",
        "    for i in range(1,n_blocks):\n",
        "        num_kernal = trial.suggest_int(\"kernal_units_l{}\".format(i), 3, 7)\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(i*num_filters2, num_kernal, activation=ac2, kernel_regularizer=reg2,padding='same'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=-1))\n",
        "        model.add(tf.keras.layers.Conv2D(i*num_filters2, num_kernal, activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "        model.add(tf.keras.layers.BatchNormalization(axis=-1))\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))   # reduces to 16x16x3xnum_filters\n",
        "        model.add(tf.keras.layers.Dropout(drop_conv2))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    for i in range(n_layers):\n",
        "        num_hidden = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128, log=True)\n",
        "        model.add(\n",
        "            tf.keras.layers.Dense(\n",
        "                num_hidden,\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
        "            )\n",
        "        )\n",
        "    model.add(\n",
        "        tf.keras.layers.Dense(CLASSES, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "syQ7goM7rgBr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_optimizer(trial):\n",
        "    # We optimize the choice of optimizers as well as their parameters.\n",
        "    kwargs = {}\n",
        "    optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n",
        "    optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n",
        "    if optimizer_selected == \"RMSprop\":\n",
        "        kwargs[\"learning_rate\"] = trial.suggest_float(\n",
        "            \"rmsprop_learning_rate\", 1e-5, 1e-1, log=True\n",
        "        )\n",
        "        kwargs[\"decay\"] = trial.suggest_float(\"rmsprop_decay\", 0.85, 0.99)\n",
        "        kwargs[\"momentum\"] = trial.suggest_float(\"rmsprop_momentum\", 1e-5, 1e-1, log=True)\n",
        "    elif optimizer_selected == \"Adam\":\n",
        "        kwargs[\"learning_rate\"] = trial.suggest_float(\"adam_learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    elif optimizer_selected == \"SGD\":\n",
        "        kwargs[\"learning_rate\"] = trial.suggest_float(\n",
        "            \"sgd_opt_learning_rate\", 1e-5, 1e-1, log=True\n",
        "        )\n",
        "        kwargs[\"momentum\"] = trial.suggest_float(\"sgd_opt_momentum\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "kcha5ubemKip"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learn(model, optimizer, dataset, mode=\"eval\"):\n",
        "    accuracy = tf.metrics.Accuracy(\"accuracy\", dtype=tf.float32)\n",
        "\n",
        "    for batch, (images, labels) in enumerate(dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(images, training=(mode == \"train\"))\n",
        "            loss_value = tf.reduce_mean(\n",
        "                tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
        "            )\n",
        "            if mode == \"eval\":\n",
        "                accuracy(\n",
        "                    tf.argmax(logits, axis=1, output_type=tf.int64), tf.cast(labels, tf.int64)\n",
        "                )\n",
        "            else:\n",
        "                #unconnected_gradients=tf.UnconnectedGradients.ZERO\n",
        "                grads = tape.gradient(loss_value, model.trainable_variables)  # use model.variables if no bacthnormalize and not need to use unconnected_gradients\n",
        "                optimizer.apply_gradients(zip(grads, model.trainable_variables)) \n",
        "\n",
        "    if mode == \"eval\":        \n",
        "        return accuracy"
      ],
      "metadata": {
        "id": "9qLLwLo8mNoo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fashion_mnist(BATCHSIZE,N_TRAIN_EXAMPLES,N_VALID_EXAMPLES):\n",
        "    (x_train, y_train), (x_valid, y_valid) = fashion_mnist.load_data()   \n",
        "\n",
        "    x_train = x_train.astype(\"float32\") / 255\n",
        "    x_valid = x_valid.astype(\"float32\") / 255\n",
        "\n",
        "    y_train = y_train.astype(\"int32\")\n",
        "    y_valid = y_valid.astype(\"int32\")\n",
        "\n",
        "    #if use conv2d\n",
        "    x_train = tf.expand_dims(x_train,axis=-1)\n",
        "    x_valid = tf.expand_dims(x_valid,axis=-1)\n",
        "    x_train  = tf.image.grayscale_to_rgb(x_train)\n",
        "    x_valid  = tf.image.grayscale_to_rgb(x_valid)\n",
        "    ##\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    train_ds = train_ds.shuffle(60000).batch(BATCHSIZE).take(N_TRAIN_EXAMPLES)\n",
        "\n",
        "    valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
        "    valid_ds = valid_ds.shuffle(10000).batch(BATCHSIZE).take(N_VALID_EXAMPLES)\n",
        "    return train_ds, valid_ds"
      ],
      "metadata": {
        "id": "tjJwDP4zmOgw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    #select batch size\n",
        "    BATCHSIZE = trial.suggest_categorical(\"n_batch\", [32,64,128,256,512,1024])\n",
        "\n",
        "    N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "    N_VALID_EXAMPLES = BATCHSIZE * 10\n",
        "\n",
        "    # Get MNIST data.\n",
        "    train_ds, valid_ds = get_fashion_mnist(BATCHSIZE,N_TRAIN_EXAMPLES,N_VALID_EXAMPLES)\n",
        "\n",
        "    # Build model and optimizer.\n",
        "    model = create_model(trial)\n",
        "    optimizer = create_optimizer(trial)\n",
        "\n",
        "    # Training and validating cycle.\n",
        "    with tf.device(\"/GPU:0\"):\n",
        "        for eporch in range(EPOCHS):\n",
        "            learn(model, optimizer, train_ds, \"train\")\n",
        "\n",
        "            accuracy = learn(model, optimizer, valid_ds, \"eval\")\n",
        "\n",
        "            trial.report(accuracy.result(),eporch) #report to optuna to check status its worth or not\n",
        "            #handing prun algo\n",
        "            if trial.should_prune():\n",
        "                raise optuna.exceptions.TrialPruned()      \n",
        "\n",
        "        # Return last validation accuracy.\n",
        "        return accuracy.result()"
      ],
      "metadata": {
        "id": "qHKYEhIymRGw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optuna Area**"
      ],
      "metadata": {
        "id": "7JgYr--mmTk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
        "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "\n",
        "print('study statistic')\n",
        "print('number of finished trials: ',len(study.trials))\n",
        "print('number of proned trials: ',len(pruned_trials))\n",
        "print('number of completed trials: ',len(complete_trials))\n",
        "\n",
        "print(\"Best trials:\")\n",
        "trial =study.best_trial\n",
        "print('Value', trial.value)\n",
        "\n",
        "print('Params')\n",
        "for key,value in trial.params.items():\n",
        "    print('{}:{}'.format(key,value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V-CZ7FEmVz_",
        "outputId": "6b6164cd-5df1-47a7-9705-448691814c17"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-04 13:46:29,441]\u001b[0m A new study created in memory with name: no-name-4750f701-5999-4a2a-a728-0b17e78bb613\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 13:49:33,957]\u001b[0m Trial 0 finished with value: 0.6317999958992004 and parameters: {'n_batch': 64, 'n_layers': 2, 'n_blocks': 3, 'weight_decay': 1.77174502023076e-07, 'kernal_units_l1': 6, 'kernal_units_l2': 3, 'n_units_l0': 37, 'n_units_l1': 37, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.00017699066735915226, 'rmsprop_decay': 0.8932610541169589, 'rmsprop_momentum': 0.006298463926655138}. Best is trial 0 with value: 0.6317999958992004.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 13:52:01,814]\u001b[0m Trial 1 finished with value: 0.9049000144004822 and parameters: {'n_batch': 32, 'n_layers': 3, 'n_blocks': 2, 'weight_decay': 5.6840367940709237e-05, 'kernal_units_l1': 3, 'n_units_l0': 28, 'n_units_l1': 23, 'n_units_l2': 58, 'optimizer': 'Adam', 'adam_learning_rate': 0.0002193370761202871}. Best is trial 1 with value: 0.9049000144004822.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 13:52:26,961]\u001b[0m Trial 2 finished with value: 0.24469999969005585 and parameters: {'n_batch': 1024, 'n_layers': 2, 'n_blocks': 2, 'weight_decay': 0.00021305328952162049, 'kernal_units_l1': 3, 'n_units_l0': 4, 'n_units_l1': 7, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 9.249128437124692e-05, 'sgd_opt_momentum': 0.00020585685805834473}. Best is trial 1 with value: 0.9049000144004822.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 13:53:05,572]\u001b[0m Trial 3 finished with value: 0.16830000281333923 and parameters: {'n_batch': 1024, 'n_layers': 1, 'n_blocks': 2, 'weight_decay': 0.00022330332812831735, 'kernal_units_l1': 6, 'n_units_l0': 49, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 1.7704094546416173e-05, 'rmsprop_decay': 0.9532257069155736, 'rmsprop_momentum': 7.007439252624082e-05}. Best is trial 1 with value: 0.9049000144004822.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 13:57:18,070]\u001b[0m Trial 4 finished with value: 0.29350000619888306 and parameters: {'n_batch': 64, 'n_layers': 3, 'n_blocks': 4, 'weight_decay': 5.132236578575276e-08, 'kernal_units_l1': 6, 'kernal_units_l2': 4, 'kernal_units_l3': 5, 'n_units_l0': 106, 'n_units_l1': 22, 'n_units_l2': 5, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.0001765012013952486, 'rmsprop_decay': 0.9714296791757415, 'rmsprop_momentum': 0.0010832665226544944}. Best is trial 1 with value: 0.9049000144004822.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 13:57:24,907]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 13:57:39,177]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 13:58:46,667]\u001b[0m Trial 7 finished with value: 0.8996999859809875 and parameters: {'n_batch': 256, 'n_layers': 3, 'n_blocks': 3, 'weight_decay': 8.131964064451251e-07, 'kernal_units_l1': 7, 'kernal_units_l2': 7, 'n_units_l0': 12, 'n_units_l1': 14, 'n_units_l2': 50, 'optimizer': 'Adam', 'adam_learning_rate': 7.820332495838309e-05}. Best is trial 1 with value: 0.9049000144004822.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:02:45,603]\u001b[0m Trial 8 finished with value: 0.9125000238418579 and parameters: {'n_batch': 64, 'n_layers': 2, 'n_blocks': 4, 'weight_decay': 0.00012847662310083897, 'kernal_units_l1': 5, 'kernal_units_l2': 7, 'kernal_units_l3': 3, 'n_units_l0': 77, 'n_units_l1': 4, 'optimizer': 'Adam', 'adam_learning_rate': 0.00023240975348195274}. Best is trial 8 with value: 0.9125000238418579.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:07:14,793]\u001b[0m Trial 9 finished with value: 0.9132999777793884 and parameters: {'n_batch': 32, 'n_layers': 3, 'n_blocks': 4, 'weight_decay': 8.218560984114148e-09, 'kernal_units_l1': 7, 'kernal_units_l2': 7, 'kernal_units_l3': 6, 'n_units_l0': 12, 'n_units_l1': 18, 'n_units_l2': 42, 'optimizer': 'Adam', 'adam_learning_rate': 0.0037431030955967035}. Best is trial 9 with value: 0.9132999777793884.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:12:19,462]\u001b[0m Trial 10 finished with value: 0.9139999747276306 and parameters: {'n_batch': 32, 'n_layers': 1, 'n_blocks': 5, 'weight_decay': 1.0059486142518816e-10, 'kernal_units_l1': 4, 'kernal_units_l2': 6, 'kernal_units_l3': 7, 'kernal_units_l4': 6, 'n_units_l0': 9, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.07139831348176875, 'sgd_opt_momentum': 0.06138453459390868}. Best is trial 10 with value: 0.9139999747276306.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:17:22,315]\u001b[0m Trial 11 finished with value: 0.921999990940094 and parameters: {'n_batch': 32, 'n_layers': 1, 'n_blocks': 5, 'weight_decay': 1.1335379782217885e-10, 'kernal_units_l1': 4, 'kernal_units_l2': 6, 'kernal_units_l3': 7, 'kernal_units_l4': 6, 'n_units_l0': 10, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09891927512386472, 'sgd_opt_momentum': 0.09564984242964526}. Best is trial 11 with value: 0.921999990940094.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:19:44,625]\u001b[0m Trial 12 finished with value: 0.9222999811172485 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 5, 'weight_decay': 2.429345622809195e-10, 'kernal_units_l1': 4, 'kernal_units_l2': 5, 'kernal_units_l3': 7, 'kernal_units_l4': 6, 'n_units_l0': 6, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09279727203690014, 'sgd_opt_momentum': 0.09007219780292347}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:22:08,020]\u001b[0m Trial 13 finished with value: 0.9150999784469604 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 5, 'weight_decay': 1.9439016535821335e-10, 'kernal_units_l1': 4, 'kernal_units_l2': 5, 'kernal_units_l3': 7, 'kernal_units_l4': 6, 'n_units_l0': 4, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.07788265088918968, 'sgd_opt_momentum': 0.09381667311214889}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:24:29,196]\u001b[0m Trial 14 finished with value: 0.9114999771118164 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 5, 'weight_decay': 1.4479196775032287e-09, 'kernal_units_l1': 4, 'kernal_units_l2': 5, 'kernal_units_l3': 6, 'kernal_units_l4': 7, 'n_units_l0': 7, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.013751011535422505, 'sgd_opt_momentum': 0.008198119606958125}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:25:40,453]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:25:49,710]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:25:57,315]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:27:28,581]\u001b[0m Trial 18 finished with value: 0.9178000092506409 and parameters: {'n_batch': 128, 'n_layers': 2, 'n_blocks': 3, 'weight_decay': 5.335090570202959e-09, 'kernal_units_l1': 5, 'kernal_units_l2': 5, 'n_units_l0': 7, 'n_units_l1': 99, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09116261009332673, 'sgd_opt_momentum': 0.0006428234645858751}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:29:04,411]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:29:35,926]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:31:06,856]\u001b[0m Trial 21 finished with value: 0.9169999957084656 and parameters: {'n_batch': 128, 'n_layers': 2, 'n_blocks': 3, 'weight_decay': 3.6982015210733323e-09, 'kernal_units_l1': 5, 'kernal_units_l2': 5, 'n_units_l0': 8, 'n_units_l1': 126, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09806636207083429, 'sgd_opt_momentum': 0.0004013706617900656}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:31:43,583]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:31:53,008]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:33:48,149]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:34:00,584]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:34:05,617]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:34:15,614]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:34:21,963]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:34:42,111]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:37:04,258]\u001b[0m Trial 30 finished with value: 0.914900004863739 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 5, 'weight_decay': 3.146792034459672e-09, 'kernal_units_l1': 3, 'kernal_units_l2': 6, 'kernal_units_l3': 5, 'kernal_units_l4': 5, 'n_units_l0': 27, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09095407487488703, 'sgd_opt_momentum': 0.0319187806923825}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:38:08,286]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:38:36,348]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:38:43,408]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:38:46,762]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:38:56,812]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:39:36,071]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:40:01,225]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:41:28,830]\u001b[0m Trial 38 finished with value: 0.9169999957084656 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 3, 'weight_decay': 2.8358475135411252e-09, 'kernal_units_l1': 4, 'kernal_units_l2': 5, 'n_units_l0': 46, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.03447420424907204, 'sgd_opt_momentum': 0.0005561734218642536}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:41:33,910]\u001b[0m Trial 39 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:41:37,422]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:42:12,438]\u001b[0m Trial 41 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:43:38,970]\u001b[0m Trial 42 finished with value: 0.920199990272522 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 3, 'weight_decay': 8.713155055609844e-09, 'kernal_units_l1': 5, 'kernal_units_l2': 5, 'n_units_l0': 113, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0470214008772526, 'sgd_opt_momentum': 0.0007596570694196618}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:45:06,432]\u001b[0m Trial 43 finished with value: 0.9068999886512756 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 3, 'weight_decay': 1.1031537957589599e-10, 'kernal_units_l1': 4, 'kernal_units_l2': 6, 'n_units_l0': 90, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.03980103815540137, 'sgd_opt_momentum': 0.0009487438772530312}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:49:02,732]\u001b[0m Trial 44 finished with value: 0.9108999967575073 and parameters: {'n_batch': 64, 'n_layers': 2, 'n_blocks': 4, 'weight_decay': 1.2214590892483354e-08, 'kernal_units_l1': 6, 'kernal_units_l2': 5, 'kernal_units_l3': 4, 'n_units_l0': 68, 'n_units_l1': 97, 'optimizer': 'Adam', 'adam_learning_rate': 0.006559224085372972}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:52:01,746]\u001b[0m Trial 45 finished with value: 0.9067999720573425 and parameters: {'n_batch': 32, 'n_layers': 1, 'n_blocks': 3, 'weight_decay': 6.35971576362846e-10, 'kernal_units_l1': 5, 'kernal_units_l2': 5, 'n_units_l0': 107, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.013589642485743259, 'sgd_opt_momentum': 0.0016453252174443917}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:52:07,853]\u001b[0m Trial 46 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:54:12,538]\u001b[0m Trial 47 finished with value: 0.9089999794960022 and parameters: {'n_batch': 128, 'n_layers': 3, 'n_blocks': 4, 'weight_decay': 7.840623033289845e-09, 'kernal_units_l1': 5, 'kernal_units_l2': 4, 'kernal_units_l3': 6, 'n_units_l0': 35, 'n_units_l1': 126, 'n_units_l2': 14, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09430479492109681, 'sgd_opt_momentum': 0.00021860257984057576}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:54:28,064]\u001b[0m Trial 48 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:54:54,416]\u001b[0m Trial 49 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:55:10,187]\u001b[0m Trial 50 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:56:36,941]\u001b[0m Trial 51 finished with value: 0.9168999791145325 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 3, 'weight_decay': 1.5738527499409144e-09, 'kernal_units_l1': 5, 'kernal_units_l2': 5, 'n_units_l0': 57, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.02721244956361414, 'sgd_opt_momentum': 0.0006174641770912986}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:58:03,550]\u001b[0m Trial 52 finished with value: 0.9190999865531921 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 3, 'weight_decay': 5.3276943453787065e-09, 'kernal_units_l1': 4, 'kernal_units_l2': 5, 'n_units_l0': 39, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.05925691413863501, 'sgd_opt_momentum': 0.0003326060528840947}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:58:21,586]\u001b[0m Trial 53 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:58:56,912]\u001b[0m Trial 54 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 14:59:06,213]\u001b[0m Trial 55 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:01:52,271]\u001b[0m Trial 56 finished with value: 0.9180999994277954 and parameters: {'n_batch': 64, 'n_layers': 1, 'n_blocks': 3, 'weight_decay': 3.8293927848506557e-10, 'kernal_units_l1': 4, 'kernal_units_l2': 6, 'n_units_l0': 77, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.008437866667856163, 'sgd_opt_momentum': 0.001617233635820382}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:03:20,955]\u001b[0m Trial 57 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:04:43,941]\u001b[0m Trial 58 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:05:18,708]\u001b[0m Trial 59 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:05:26,511]\u001b[0m Trial 60 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:05:32,685]\u001b[0m Trial 61 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:05:49,805]\u001b[0m Trial 62 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:06:26,483]\u001b[0m Trial 63 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:07:28,002]\u001b[0m Trial 64 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:08:55,570]\u001b[0m Trial 65 finished with value: 0.916100025177002 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 3, 'weight_decay': 3.7292189291351435e-10, 'kernal_units_l1': 4, 'kernal_units_l2': 5, 'n_units_l0': 47, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.02862989682612483, 'sgd_opt_momentum': 0.0006107706464802408}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:09:00,943]\u001b[0m Trial 66 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:09:26,789]\u001b[0m Trial 67 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:09:34,702]\u001b[0m Trial 68 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:09:52,126]\u001b[0m Trial 69 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:10:51,917]\u001b[0m Trial 70 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:11:27,159]\u001b[0m Trial 71 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:11:36,700]\u001b[0m Trial 72 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:12:37,994]\u001b[0m Trial 73 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:12:47,373]\u001b[0m Trial 74 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:13:05,549]\u001b[0m Trial 75 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:13:10,827]\u001b[0m Trial 76 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:13:17,043]\u001b[0m Trial 77 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:13:42,781]\u001b[0m Trial 78 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:13:45,908]\u001b[0m Trial 79 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:13:55,522]\u001b[0m Trial 80 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:15:15,073]\u001b[0m Trial 81 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:15:50,758]\u001b[0m Trial 82 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:17:18,075]\u001b[0m Trial 83 finished with value: 0.9154000282287598 and parameters: {'n_batch': 128, 'n_layers': 1, 'n_blocks': 3, 'weight_decay': 3.806707407272776e-09, 'kernal_units_l1': 5, 'kernal_units_l2': 5, 'n_units_l0': 37, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.044145157464429485, 'sgd_opt_momentum': 0.0011272093540421121}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:17:53,571]\u001b[0m Trial 84 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:18:03,343]\u001b[0m Trial 85 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:18:18,387]\u001b[0m Trial 86 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:18:52,185]\u001b[0m Trial 87 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:19:11,244]\u001b[0m Trial 88 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:19:59,702]\u001b[0m Trial 89 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:21:39,384]\u001b[0m Trial 90 finished with value: 0.9189000129699707 and parameters: {'n_batch': 128, 'n_layers': 3, 'n_blocks': 3, 'weight_decay': 8.858479059479691e-10, 'kernal_units_l1': 5, 'kernal_units_l2': 5, 'n_units_l0': 41, 'n_units_l1': 8, 'n_units_l2': 111, 'optimizer': 'Adam', 'adam_learning_rate': 0.0013528373202400749}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:23:18,952]\u001b[0m Trial 91 finished with value: 0.9217000007629395 and parameters: {'n_batch': 128, 'n_layers': 3, 'n_blocks': 3, 'weight_decay': 8.028213469535871e-10, 'kernal_units_l1': 5, 'kernal_units_l2': 5, 'n_units_l0': 40, 'n_units_l1': 7, 'n_units_l2': 121, 'optimizer': 'Adam', 'adam_learning_rate': 0.0013003244427342222}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:23:59,246]\u001b[0m Trial 92 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:25:38,561]\u001b[0m Trial 93 finished with value: 0.920799970626831 and parameters: {'n_batch': 128, 'n_layers': 3, 'n_blocks': 3, 'weight_decay': 1.4506081913062557e-10, 'kernal_units_l1': 5, 'kernal_units_l2': 5, 'n_units_l0': 34, 'n_units_l1': 7, 'n_units_l2': 123, 'optimizer': 'Adam', 'adam_learning_rate': 0.0009821756169891426}. Best is trial 12 with value: 0.9222999811172485.\u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:25:59,006]\u001b[0m Trial 94 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:26:19,442]\u001b[0m Trial 95 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:26:24,772]\u001b[0m Trial 96 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:26:40,971]\u001b[0m Trial 97 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:26:47,080]\u001b[0m Trial 98 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-05-04 15:28:03,500]\u001b[0m Trial 99 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "study statistic\n",
            "number of finished trials:  100\n",
            "number of proned trials:  70\n",
            "number of completed trials:  30\n",
            "Best trials:\n",
            "Value 0.9222999811172485\n",
            "Params\n",
            "n_batch:128\n",
            "n_layers:1\n",
            "n_blocks:5\n",
            "weight_decay:2.429345622809195e-10\n",
            "kernal_units_l1:4\n",
            "kernal_units_l2:5\n",
            "kernal_units_l3:7\n",
            "kernal_units_l4:6\n",
            "n_units_l0:6\n",
            "optimizer:SGD\n",
            "sgd_opt_learning_rate:0.09279727203690014\n",
            "sgd_opt_momentum:0.09007219780292347\n"
          ]
        }
      ]
    }
  ]
}